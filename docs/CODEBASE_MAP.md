---
last_mapped: 2026-02-12T00:00:00Z
total_files: 139
total_tokens: 390574
---

# AuraIO Codebase Map

> Auto-generated by Cartographer. Last mapped: 2026-02-12

## System Overview

AuraIO (Adaptive Uring Runtime Architecture) is a self-tuning asynchronous I/O library for Linux built on io_uring. It uses AIMD (Additive Increase Multiplicative Decrease) congestion control to automatically optimize I/O parameters for throughput and latency. The library provides C11, C++20, and Rust APIs.

```mermaid
graph TB
    subgraph "Public APIs"
        CAPI[engine/include/auraio.h<br/>C API]
        CPPAPI[engine/include/auraio.hpp<br/>C++ API]
        RustAPI[auraio crate<br/>Rust API]
    end

    subgraph "C++ Bindings"
        Engine[engine.hpp<br/>Engine class]
        Coro[coro.hpp<br/>Coroutines]
        CppBuf[buffer.hpp<br/>RAII buffers]
    end

    subgraph "Rust Bindings"
        RustSafe[auraio crate<br/>Safe wrapper]
        RustAsync[async_io.rs<br/>Futures]
        RustSys[auraio-sys<br/>FFI bindings]
    end

    subgraph "Integrations"
        Prom[prometheus/C<br/>Text exposition]
        OTel[opentelemetry/C<br/>OTLP/JSON]
        Syslog[syslog/C<br/>Syslog forwarding]
        PromCpp[prometheus/cpp<br/>Planned]
        OTelCpp[opentelemetry/cpp<br/>Planned]
        PromRust[prometheus/rust<br/>Planned]
        OTelRust[opentelemetry/rust<br/>Planned]
    end

    subgraph "Core C Library"
        Impl[auraio.c<br/>Implementation]
        Ring[adaptive_ring.c<br/>io_uring wrapper]
        Adaptive[adaptive_engine.c<br/>AIMD controller]
        BufPool[adaptive_buffer.c<br/>Buffer pool]
        Log[log.c<br/>Log callback]
    end

    subgraph "External"
        liburing[liburing]
        Kernel[Linux Kernel<br/>io_uring]
    end

    CPPAPI --> Engine
    Engine --> Coro
    Engine --> CppBuf
    Engine --> CAPI
    RustAPI --> RustSafe
    RustSafe --> RustAsync
    RustSafe --> RustSys
    RustSys --> CAPI
    Prom --> CAPI
    OTel --> CAPI
    CAPI --> Impl
    Impl --> Ring
    Impl --> Adaptive
    Impl --> BufPool
    Impl --> Log
    Ring --> Adaptive
    Ring --> liburing
    liburing --> Kernel
```

## Recent Changes (Since 2026-02-09)

### Performance Optimizations (Commits 1138130, ee30f98)
- **Rwlock fast path**: Skip rwlock acquisition when no buffers/files registered (~4.9% CPU saved)
- **Eventfd skip**: Skip eventfd drain in single-thread mode (~5% improvement)
- **Combined impact**: ~9.6% IOPS increase (1,081K → 1,185K)
- **Batch completion retirement**: Reduced lock acquisitions from N-per-completion to 1-per-batch (up to 32 CQEs)
- **Single-thread fast path**: New `single_thread` option skips mutexes (~1-2% IOPS)

### AIMD Improvements (Commits 3cf1e3f, c14a692)
- **Target-P99 probing**: Continue probing when P99 < target, even at throughput plateau
  - Allows AIMD to reach full system saturation when latency headroom exists
  - BFFIO benchmark improved from -30% vs FIO (depth 48) to -10% vs FIO (depth 881)
- **Peak in-flight tracking**: New metric tracks actual observed peak `pending_count` via high-water mark
  - Replaces `optimal_in_flight` ceiling which violated Little's Law
  - Zero hot-path overhead (updated by tick thread)

### API Changes (Commit e604030)
- **Fsync consolidation**: Merged `aura_fsync()` and `aura_fsync_ex()` into single function
  - Takes `aura_fsync_flags_t` parameter: `AURA_FSYNC_DEFAULT` or `AURA_FSYNC_DATASYNC`
  - Cleaner, more extensible API surface

### New Features
- **Log handling API** (Commits db1dc7a, aa25c98):
  - Cross-language log infrastructure (C, C++, Rust)
  - `aura_log_emit()` for application logging
  - Examples: `examples/{C,cpp,rust}/log_handler.{c,cpp,rs}`
- **Syslog integration** (Commit 68aa27f):
  - Turnkey syslog forwarding: `integrations/syslog/C/`
  - 1:1 level mapping, configurable ident/facility
- **BFFIO multi-file support** (Commit 19f97f7):
  - New parameters: `nrfiles`, `filesize`, `file_service_type` (roundrobin/sequential/random)
  - Adaptive latency sampling (~100K samples/sec ceiling, commit 4c5fb01)

### New Tests & Tools
- **adaptive_value.c** (Commit f4c6624): Proves AIMD value across 3 scenarios
  - Noisy neighbor, P99-constrained throughput, workload phase change
- **perf_regression.c** (Commit 6588b04): Measures AuraIO overhead vs raw io_uring
  - Optimized baseline with COOP_TASKRUN, SINGLE_ISSUER, merged syscalls
  - Documents 19% structural overhead (mutexes, atomics, request pool)
- **Coverage infrastructure** (Commit edf0910): `build-tools/coverage/run_llvm_cov.sh`
  - Auto-detects clang >= 18, generates 4 report formats, CI-ready minimum coverage enforcement

### Project Structure (Commit edf0910, 741ee7b)
- **Directory reorganization**: `src/` → `engine/src/`, `include/` → `engine/include/`
- **Integration rename**: `exporters/` → `integrations/`
- **Tooling removed**: API surface snapshots and RFC process (dead code after restructuring)
- **Version bump**: v0.2.0 (structural changes only, no API breakage)

## Directory Structure

```
AuraIO/
├── engine/                     # C library + C++ header-only bindings
│   ├── include/
│   │   ├── auraio.h              # Public C API (opaque types, all user-facing functions)
│   │   ├── auraio.hpp            # C++ umbrella header
│   │   └── auraio/
│   │       ├── engine.hpp        # Engine class with callbacks
│   │       ├── coro.hpp          # C++20 coroutine support (Task<T>, awaitables)
│   │       ├── buffer.hpp        # RAII buffer wrappers
│   │       ├── log.hpp           # C++ log API (NEW in v0.2.0)
│   │       ├── options.hpp       # Configuration wrapper
│   │       ├── request.hpp       # Request wrapper
│   │       ├── stats.hpp         # Stats wrapper
│   │       ├── error.hpp         # Exception types
│   │       ├── fwd.hpp           # Forward declarations
│   │       └── detail/
│   │           └── callback_storage.hpp  # Type-erased callback pool
│   ├── src/
│   │   ├── auraio.c              # Public API implementation, ring selection, event loop
│   │   ├── adaptive_ring.c       # io_uring wrapper, request pool, completion handling
│   │   ├── adaptive_ring.h       # Ring internal interface
│   │   ├── adaptive_engine.c     # AIMD algorithm, P99 tracking, phase state machine
│   │   ├── adaptive_engine.h     # Adaptive controller interface, tuning constants
│   │   ├── adaptive_buffer.c     # Thread-safe aligned buffer pool with sharding
│   │   ├── adaptive_buffer.h     # Buffer pool interface
│   │   ├── log.c                 # Library-wide log callback implementation
│   │   ├── log.h                 # Internal log header (aura_log_fn, aura_log)
│   │   └── internal.h            # Shared utilities (timing, iovec helpers)
│   ├── lib/                  # Compiled libraries (git-ignored)
│   └── pkg/                  # Packaging templates
│       └── libauraio.pc.in
├── bindings/
│   └── rust/
│       ├── Cargo.toml        # Workspace: auraio-sys + auraio
│       ├── auraio-sys/       # Raw FFI bindings (bindgen-generated)
│       │   ├── build.rs      # Library detection + bindgen codegen
│       │   └── src/lib.rs    # Re-exports generated bindings
│       └── auraio/           # Safe Rust wrapper
│           └── src/
│               ├── lib.rs        # Public API re-exports, integration tests
│               ├── engine.rs     # Engine RAII wrapper, I/O methods
│               ├── buffer.rs     # Buffer (RAII) + BufferRef (Copy)
│               ├── callback.rs   # Type-erased FFI trampoline
│               ├── async_io.rs   # AsyncEngine trait, IoFuture
│               ├── log.rs        # Rust log API (NEW in v0.2.0)
│               ├── options.rs    # Builder-pattern config
│               ├── request.rs    # RequestHandle (pending op)
│               ├── error.rs      # Error enum (thiserror)
│               └── stats.rs      # Stats snapshot
├── integrations/             # External system integrations
│   ├── prometheus/
│   │   ├── C/                    # ✅ Implemented
│   │   │   ├── aura_prometheus.h   # Prometheus formatter API
│   │   │   ├── aura_prometheus.c   # Text exposition format implementation
│   │   │   └── example.c             # Minimal HTTP server on :9091/metrics
│   │   ├── cpp/                  # ⏳ Planned (README placeholder)
│   │   └── rust/                 # ⏳ Planned (README placeholder)
│   ├── opentelemetry/
│   │   ├── C/                    # ✅ Implemented
│   │   │   ├── aura_otel.h         # OTLP/JSON formatter API
│   │   │   ├── aura_otel.c         # OTLP JSON format implementation
│   │   │   ├── aura_otel_push.h    # HTTP push helper API
│   │   │   ├── aura_otel_push.c    # Blocking HTTP POST to OTel collector
│   │   │   └── example.c             # Periodic push loop with --dry-run
│   │   ├── cpp/                  # ⏳ Planned (README placeholder)
│   │   └── rust/                 # ⏳ Planned (README placeholder)
│   └── syslog/
│       └── C/                    # ✅ NEW in v0.2.0
│           ├── aura_syslog.h       # Syslog integration API
│           ├── aura_syslog.c       # Syslog forwarder implementation
│           └── example.c             # Usage demo with custom ident
├── examples/
│   ├── C/
│   │   ├── quickstart.c      # Minimal read example
│   │   ├── simple_read.c     # Single file read with stats
│   │   ├── bulk_reader.c     # High-throughput directory scanner
│   │   ├── write_modes.c     # O_DIRECT vs buffered comparison
│   │   ├── cancel_request.c  # In-flight request cancellation demo
│   │   ├── custom_config.c   # 5 workload configurations
│   │   ├── vectored_io.c     # Scatter-gather readv/writev
│   │   ├── registered_buffers.c  # Zero-copy with pre-registered buffers
│   │   ├── file_copy.c       # Synchronous-style file copy
│   │   └── log_handler.c     # Custom log handler demo (NEW in v0.2.0)
│   ├── cpp/
│   │   ├── quickstart.cpp    # Minimal C++ async read
│   │   ├── simple_read.cpp   # C++ version of simple read
│   │   ├── bulk_reader.cpp   # C++ high-throughput scanner
│   │   ├── write_modes.cpp   # C++ write modes demo
│   │   ├── cancel_request.cpp  # C++ cancellation demo
│   │   ├── custom_config.cpp # C++ workload tuning
│   │   ├── vectored_io.cpp   # C++ scatter-gather
│   │   ├── registered_buffers.cpp  # C++ zero-copy demo
│   │   ├── coroutine_copy.cpp # C++20 coroutine file copy
│   │   └── log_handler.cpp   # C++ log handler demo (NEW in v0.2.0)
│   ├── rust/
│   │   └── examples/
│   │       ├── quickstart.rs     # Minimal Rust async read
│   │       ├── simple_read.rs    # Read with stats reporting
│   │       ├── bulk_reader.rs    # Concurrent directory scanner
│   │       ├── file_copy.rs      # Synchronous-style file copy
│   │       ├── async_copy.rs     # Future-based async file copy
│   │       ├── write_modes.rs    # O_DIRECT vs buffered comparison
│   │       ├── cancel_request.rs # Rust cancellation demo
│   │       ├── custom_config.rs  # Rust workload tuning
│   │       ├── vectored_io.rs    # Rust scatter-gather
│   │       ├── registered_buffers.rs  # Rust zero-copy demo
│   │       └── log_handler.rs    # Rust log handler demo (NEW in v0.2.0)
│   └── README.md             # Examples cross-reference guide
├── build-tools/                # Development infrastructure (NEW in v0.2.0)
│   ├── coverage/
│   │   └── run_llvm_cov.sh       # Coverage automation with CI enforcement
│   └── deps/
│       ├── check.sh              # Validate development environment dependencies
│       └── install_all.sh        # One-command dependency installation (apt-based)
├── tools/
│   ├── bin/                      # Compiled tool binaries (NEW in v0.2.0)
│   └── BFFIO/                    # FIO-compatible I/O benchmark (powered by AuraIO)
│       ├── main.c               # CLI entry point, engine lifecycle
│       ├── job_parser.h/.c      # .fio INI parser + CLI arg parser (multi-file support NEW)
│       ├── workload.h/.c        # I/O loop, worker threads, file management (adaptive sampling NEW)
│       ├── stats.h/.c           # Latency histograms, percentiles, aggregation
│       ├── output.h/.c          # FIO-compatible text + JSON formatters
│       ├── test_BFFIO.sh        # Functional test suite (20+ tests)
│       ├── run_baseline.sh      # FIO vs BFFIO comparison with delta report
│       ├── README.md            # Overview and quick usage (NEW in v0.2.0)
│       ├── USAGE.md             # Comprehensive usage guide (NEW in v0.2.0)
│       └── Makefile
├── tests/
│   ├── test_engine.c         # AIMD algorithm tests
│   ├── test_ring.c           # Ring management tests
│   ├── test_buffer.c         # Buffer pool tests
│   ├── test_stats.c          # Observability API tests
│   ├── test_ring_select.c    # Ring selection mode tests (ADAPTIVE/CPU_LOCAL/ROUND_ROBIN)
│   ├── test_cpp.cpp          # C++ binding tests
│   ├── stress_test.cpp       # Multi-threaded stress test
│   ├── perf_bench.c          # Performance benchmarks (throughput, latency, scalability)
│   ├── bench_buffer.c        # Buffer pool microbenchmark
│   ├── test_concurrency_stress.c # Concurrency stress test
│   ├── test_coverage.c       # Comprehensive coverage test suite
│   ├── test_otel.c           # OpenTelemetry exporter tests
│   ├── adaptive_value.c      # AIMD value proof: 3 scenarios (NEW in v0.2.0)
│   ├── perf_regression.c     # AuraIO vs raw io_uring overhead measurement (NEW in v0.2.0)
│   ├── run_analysis.sh       # FIO comparison benchmark suite
│   ├── run_deep_analysis.sh  # Flamegraph/cachegrind/pahole profiling
│   ├── run_perf_test.sh      # Portable benchmark runner
│   ├── coverage/             # Coverage reports (relocated from root in v0.2.0)
│   └── Makefile
├── investigations/           # Performance analysis docs (NEW in v0.2.0)
│   └── bffio-performance-gap.md  # Root cause analysis of BFFIO vs FIO gap
├── docs/
│   ├── api_reference.md      # Complete C and C++ API reference
│   ├── architecture.md       # Design philosophy, concurrency model, migration guide
│   ├── ASYNC_LIFECYCLE.md    # Two-phase error model, request handle lifetime
│   ├── BFFIO.md              # BFFIO benchmark tool usage and architecture
│   ├── COMPATIBILITY_POLICY.md # Pre-1.0/post-1.0 API stability rules
│   ├── observability.md      # Metrics API, Prometheus, sampling cost analysis
│   ├── OBSERVABILITY_CONTRACT.md # Prometheus schema versioning, metric contracts
│   └── performance.md        # Hardware-aware I/O design, internal optimizations
├── Makefile                   # Main build system
└── README.md                  # User documentation
```

## Module Guide

### Public C API (`engine/include/auraio.h` + `engine/src/auraio.c`)

**Purpose**: User-facing C interface tying together rings, buffers, and adaptive control

**Entry point**: `engine/include/auraio.h`

| File | Purpose | Tokens |
|------|---------|--------|
| `engine/include/auraio.h` | Public types and function declarations | 8,317 |
| `engine/src/auraio.c` | API implementation, ring selection modes, merged flush+poll | 15,434 |

**Key Types**:
- `aura_engine_t` - Opaque engine handle
- `aura_request_t` - Opaque request handle
- `aura_buf_t` - Unified buffer descriptor (regular or registered)
- `aura_callback_t` - Completion callback: `void (*)(aura_request_t*, ssize_t, void*)` (NULL valid for fire-and-forget)
- `aura_fsync_flags_t` - Fsync variant enum: `DEFAULT`, `DATASYNC`
- `aura_stats_t` - Statistics snapshot (includes `adaptive_spills` counter)
- `aura_ring_stats_t` - Per-ring metrics (ops, bytes, in_flight_limit, p99, aimd_phase)
- `aura_histogram_t` - Latency histogram (200 buckets x 50us, 0-10ms range)
- `aura_buffer_stats_t` - Buffer pool stats (allocated bytes, buffers, shards)
- `aura_options_t` - Engine configuration (includes `ring_select` mode)
- `aura_ring_select_t` - Ring selection mode enum: `ADAPTIVE`, `CPU_LOCAL`, `ROUND_ROBIN`

**Key Functions**:
- Lifecycle: `aura_create()`, `aura_create_with_options()`, `aura_destroy()`
- I/O: `aura_read()`, `aura_write()`, `aura_readv()`, `aura_writev()`, `aura_fsync()`
- Event loop: `aura_poll()`, `aura_wait()`, `aura_run()`, `aura_stop()`, `aura_drain()`
- Buffers: `aura_buffer_alloc()`, `aura_buffer_free()`
- Registered I/O: `aura_register_buffers()`, `aura_unregister_buffers()`, `aura_request_unregister_buffers()`, `aura_register_files()`, `aura_unregister_files()`, `aura_request_unregister_files()`, `aura_update_file()`
- Observability: `aura_get_stats()`, `aura_get_ring_stats()`, `aura_get_histogram()`, `aura_get_buffer_stats()`, `aura_get_ring_count()`
- Cancellation: `aura_cancel()`
- Logging: `aura_set_log_handler()` (new in latest version)
- Version: `aura_version()`, `aura_version_int()`, `aura_phase_name()`

**Ring Selection Modes**:
- **ADAPTIVE** (default): CPU-local with power-of-two spilling. Gate 1: spill if local ring pending >= 75% of in-flight limit. Gate 2: stay local if pending > 2x global average (outlier). Spill target: pick 2 random non-local rings, use lighter one.
- **CPU_LOCAL**: Strict CPU-affinity via TLS-cached `sched_getcpu()`. Best NUMA locality, no cross-ring traffic.
- **ROUND_ROBIN**: Atomic fetch-add counter for even distribution across all rings. Maximum single-thread scaling.

**Optimizations**:
- TLS-cached `sched_getcpu()` in `select_ring()` (refreshed every 32 submissions)
- Thread-local xorshift32 PRNG for power-of-two ring selection
- Merged flush+poll in `aura_wait()` with early exit on first completion
- Eventfd draining to prevent spurious epoll wakeups
- Drift-free tick thread using `clock_nanosleep()` with `TIMER_ABSTIME`

**Fatal Submit Error Latching**: First fatal `ring_flush()` error (not EAGAIN/EBUSY/EINTR) is latched atomically via `fatal_submit_errno`. All subsequent submissions fail immediately with the latched errno. The event loop is woken via eventfd to propagate the error. `aura_poll()`/`aura_wait()` return the error only after draining all pending completions.

**Submit Begin/End/Abort Pattern**: All I/O submission functions use a centralized `submit_begin()`/`submit_end()`/`submit_abort()` pattern that handles: fatal error checking, shutdown detection (`ESHUTDOWN`), ring lock acquisition, request slot allocation, conditional flushing, and guaranteed lock release on all paths.

**Registered Buffer Protection**: `pthread_rwlock_t reg_lock` serializes buffer/file registration with in-flight I/O. Read lock held during submission validation; write lock during register/unregister. Overflow-safe bounds checking: `offset >= iov_len || len > iov_len - offset` (prevents integer overflow). `aura_destroy()` drains all pending I/O **before** unregistering buffers.

**Transparent Fixed-File Resolution**: Regular I/O calls automatically use registered files when available via `resolve_registered_file_locked()`. The caller need not use special APIs.

**Callback-Safe Unregister**: `aura_request_unregister_buffers()` / `aura_request_unregister_files()` enable deferred unregistration safe to call from completion callbacks. The synchronous variants (`aura_unregister_buffers()` / `aura_unregister_files()`) auto-detect callback context and degrade to deferred mode when needed. During drain, fixed-buffer submissions return `EBUSY`. Per-ring `fixed_buf_inflight` atomic counters track in-flight registered buffer ops for safe finalization. Finalization is checked in `aura_poll()`, `aura_wait()`, and `aura_drain()`.

**Destroy Ordering**: `aura_destroy()` follows strict ordering: (1) set `shutting_down` flag, (2) stop tick thread via `atomic_exchange` (prevents double-join), (3) stop event loop, (4) drain all pending I/O, (5) unregister buffers/files, (6) destroy rings and buffer pool.

**Dependencies**: All internal modules, liburing, pthread, eventfd

**Thread Safety**: Multiple threads can submit concurrently (per-ring locks); single thread should poll

---

### C++ Bindings (`engine/include/auraio.hpp` + `engine/include/auraio/*.hpp`)

**Purpose**: Modern C++20 interface with RAII, exceptions, concepts, and coroutines

**Entry point**: `engine/include/auraio.hpp`

| File | Purpose | Tokens |
|------|---------|--------|
| `engine/include/auraio.hpp` | Umbrella header | 427 |
| `engine/include/auraio/engine.hpp` | Engine class, callbacks, concepts, per-ring stats, deferred unregister | 4,688 |
| `engine/include/auraio/coro.hpp` | Task<T>, IoAwaitable, FsyncAwaitable | 3,250 |
| `engine/include/auraio/buffer.hpp` | Buffer (RAII), BufferRef (explicit const ctor), engine lifetime tracking | 2,546 |
| `engine/include/auraio/options.hpp` | Options wrapper with RingSelect | 1,242 |
| `engine/include/auraio/request.hpp` | Request wrapper | 442 |
| `engine/include/auraio/stats.hpp` | Stats, RingStats, Histogram, BufferStats | 1,316 |
| `engine/include/auraio/error.hpp` | auraio::Error exception | 476 |
| `engine/include/auraio/fwd.hpp` | Forward declarations | 94 |
| `engine/include/auraio/detail/callback_storage.hpp` | 8-shard CallbackPool, type erasure | 2,135 |

**Key Classes**:
- `auraio::Engine` - **Non-movable** engine wrapper (locked `event_loop_mutex_` can't move); use `std::unique_ptr<Engine>` for heap allocation
- `auraio::Buffer` - RAII buffer owner (returns to pool on destruction)
- `auraio::BufferRef` - Lightweight buffer descriptor (explicit const ctor for safety)
- `auraio::Options` - Builder with `ring_select(RingSelect)` setter
- `auraio::RingSelect` - Enum: `Adaptive`, `CpuLocal`, `RoundRobin`
- `auraio::Stats` - Stats snapshot with `adaptive_spills()` getter
- `auraio::RingStats` - Per-ring metrics with `aimd_phase_name()` helper
- `auraio::Histogram` - Latency histogram with bucket accessors
- `auraio::BufferStats` - Buffer pool stats
- `auraio::Request` - Request wrapper
- `auraio::Error` - Exception with errno; predicates: `is_invalid()`, `is_again()`, `is_not_found()`, `is_cancelled()`, `is_busy()`

**Coroutine Support** (C++20):
- `Task<T>` - Lazy coroutine returning T; destructor calls `std::terminate()` if still pending (fail-fast, not UB)
- `IoAwaitable` - Awaitable for read/write (yields `ssize_t`); `completed_` atomic coordinates callback vs `await_suspend`
- `FsyncAwaitable` - Awaitable for fsync (yields `void`)
- Result consumption is destructive (`get()` moves out, subsequent calls throw)
- Uses `make_unsigned_t` cast in error conversion to avoid signed overflow UB on `SSIZE_MIN`

**Engine Destruction Safety**:
- `engine_alive_` set to `false` **before** calling `aura_destroy()` — prevents race where concurrent Buffer destructor calls `aura_buffer_free()` on freed engine handle
- Buffers that outlive the engine fall back to `free()` instead of pool return

**Patterns**:
- Type-erased callbacks via `std::function` + trampoline
- 8-shard `CallbackPool` for reduced mutex contention on many-core systems
- Non-movable semantics prevent accidentally moving a locked engine
- Thread-local shard assignment via thread ID hash
- `event_loop_mutex_` serializes `poll()`/`wait()`/`run()` (submissions remain lock-free)
- Deferred unregister: `request_unregister_buffers()` / `request_unregister_files()`
- O(1) callback cleanup: `on_complete` lambda set **before** submission (callback can fire immediately)

---

### Rust Bindings (`bindings/rust/`)

**Purpose**: Safe, idiomatic Rust wrapper with RAII, async/await, and zero-cost abstractions

**Entry point**: `bindings/rust/auraio/src/lib.rs`

| File | Purpose | Tokens |
|------|---------|--------|
| `auraio-sys/build.rs` | Library detection + bindgen codegen | 835 |
| `auraio-sys/src/lib.rs` | Raw FFI re-exports | 449 |
| `auraio/src/lib.rs` | Public API, integration tests | 8,918 |
| `auraio/src/engine.rs` | Engine RAII wrapper, all I/O methods, deferred unregister | 5,545 |
| `auraio/src/async_io.rs` | AsyncEngine trait, IoFuture, cancellation safety | 4,995 |
| `auraio/src/buffer.rs` | Buffer (RAII, Drop) + BufferRef (Copy) | 1,903 |
| `auraio/src/callback.rs` | BoxedCallback, FFI trampoline, panic catch | 516 |
| `auraio/src/options.rs` | Builder-pattern config with RingSelect | 855 |
| `auraio/src/request.rs` | RequestHandle (pending op) | 931 |
| `auraio/src/error.rs` | Error enum via thiserror | 278 |
| `auraio/src/stats.rs` | Stats snapshot | 1,445 |

**Architecture**:
```
Application
    ↓
auraio crate (safe API: Engine, Buffer, AsyncEngine)
    ↓
auraio-sys crate (raw FFI, bindgen-generated)
    ↓
libauraio.so (C library)
```

**Key Types**:
- `Engine` - RAII wrapper (`Send + Sync`), `Arc<EngineInner>` for shared ownership with `IoFuture`; destroyed on `Drop`
- `Buffer` - RAII pool buffer (`Send`, not `Sync`), freed on `Drop`
- `BufferRef` - Lightweight descriptor (`Copy`), no ownership
- `AsyncEngine` - Extension trait adding `async_read()`, `async_write()`, `async_fsync()`, `async_fdatasync()`, `async_readv()`, `async_writev()`
- `IoFuture` - Runtime-agnostic future for async I/O; explicitly `Send`
- `Options` - Builder with chainable setters including `ring_select(RingSelect)`
- `RingSelect` - Enum: `Adaptive`, `CpuLocal`, `RoundRobin`
- `Error` - `Io`, `EngineCreate`, `BufferAlloc`, `Submission`, `Cancelled`, `InvalidArgument`

**Callback Flow**:
1. Rust closure boxed as `BoxedCallback` (`Box<dyn FnOnce(Result<usize>) + Send>`)
2. `Box::into_raw()` transfers ownership to C library via `user_data` pointer
3. C library invokes `callback_trampoline()` on completion
4. Trampoline calls `Box::from_raw()`, invokes closure, drops context
5. Panics caught at FFI boundary via `catch_unwind` (prevents cross-FFI unwinding)

**Async Pattern**:
- `AsyncEngine` methods return `IoFuture` (shared `Arc<Mutex<IoState>>`)
- Callback stores result + invokes `Waker`
- Requires background thread calling `engine.wait()` to make progress
- Runtime-agnostic: no tokio/async-std dependency

**Async Cancellation Safety**:
- `request_consumed: Arc<AtomicBool>` prevents use-after-free in `IoFuture::drop()`
- Set to `true` with `Release` ordering **before** callback acquires the state mutex
- `IoFuture::drop()` checks `request_consumed` before calling `aura_cancel()` — prevents cancelling a request whose handle is already invalid
- Lock dropped before FFI calls and `Waker::wake()` to prevent deadlock
- All mutex locks use `.unwrap_or_else(|e| e.into_inner())` for poisoned-mutex robustness

**Engine Lifetime**:
- `Engine::inner` is `Arc<EngineInner>`, shared with `IoFuture` instances
- `poll_lock: Mutex<()>` serializes poll/wait/run (submissions remain lock-free)
- errno captured **before** cleanup `drop()` calls (drop could clobber errno)
- Deadlock warnings: never call poll/wait/run from within a completion callback

**Deferred Unregistration**:
- `request_unregister_buffers()` / `request_unregister_files()` — callback-safe lazy unregister

**Gotchas**:
- `RequestHandle` becomes **invalid** after callback starts (dangling pointer)
- Inline C functions (`aura_buf`, `aura_buf_fixed`) reimplemented in Rust (bindgen can't handle inline)
- Async futures don't progress without `engine.wait()` calls
- `wrapping_neg()` used for errno conversion to avoid overflow panic on `isize::MIN`
- Dropping `IoFuture` does **not** cancel the kernel operation (buffer must outlive kernel I/O)

---

### Prometheus Integration (`integrations/prometheus/C/`)

**Purpose**: Standalone Prometheus text exposition format formatter for AuraIO metrics (zero external dependencies)

| File | Purpose | Tokens |
|------|---------|--------|
| `aura_prometheus.h` | Formatter API, schema version constants | 444 |
| `aura_prometheus.c` | Text format implementation | 2,576 |
| `example.c` | HTTP server on :9091 | 1,280 |

**API**: `aura_metrics_prometheus(engine, buf, buf_size)` — returns bytes written (clamped to `INT_MAX`), or negative on error

**Return Contract**:
- Success: bytes written (0 to `INT_MAX`)
- Buffer too small: negative estimate with `errno=ENOBUFS` (retriable — allocate `abs(return_value)` bytes)
- Hard failure: -1 with `errno=ENOMEM` (not retriable)

**Metrics exported** (30+):
- Aggregate: ops_completed, bytes_transferred, throughput, p99_latency, in_flight, ring_count, adaptive_spills
- Per-ring: ops, bytes, in_flight, in_flight_limit, batch_threshold, queue_depth, p99, throughput, aimd_phase
- Per-ring histograms: latency distribution with cumulative buckets (only non-zero buckets emitted)
- Buffer pool: allocated_bytes, buffers, shards

**Patterns**:
- `PROM_APPEND` macro for safe buffer building with overflow detection
- `size_t` accumulation with `INT_MAX` clamping prevents integer overflow on large outputs
- NaN/Inf clamped to 0.0 (Prometheus format compliance)
- Cumulative histogram buckets (per Prometheus spec)
- Schema versioning: `AURA_PROMETHEUS_SCHEMA_VERSION` ("v0"), `AURA_PROMETHEUS_SCHEMA_STABILITY` ("experimental")
- Emits `aura_metrics_schema_info` metric for schema discovery
- OOM returns `ENOMEM` (-1) rather than jumping to overflow label
- No external dependencies beyond libc

**Gotchas**:
- Histogram sum is estimated using bucket midpoints (not exact)
- On overflow, returns `-(written * 2 + 4096)` as conservative retry estimate (clamped to `INT_MIN` if needed)
- Example server is demo-quality (not production-grade, best-effort writes)

---

### OpenTelemetry Integration (`integrations/opentelemetry/C/`)

**Purpose**: OTLP/JSON metrics formatter and HTTP push helper for AuraIO metrics (zero external dependencies)

| File | Purpose | Tokens |
|------|---------|--------|
| `aura_otel.h` | Formatter API, schema version constants | 438 |
| `aura_otel.c` | OTLP JSON format implementation | 3,662 |
| `aura_otel_push.h` | HTTP push helper API | 290 |
| `aura_otel_push.c` | Blocking HTTP POST to OTel collector | 1,651 |
| `example.c` | Periodic push loop with --dry-run | 881 |

**API**: `aura_metrics_otel(engine, buf, buf_size)` — returns bytes written, or negative on error (same contract as Prometheus exporter)

**Push API**: `aura_otel_push(endpoint, buf, len)` — returns HTTP status code (200 = success), or -1 on error

**OTLP Mapping**:
- Monotonic cumulative sums: ops_completed, bytes_transferred, adaptive_spills
- Gauges: throughput, p99_latency, in_flight, optimal_in_flight, optimal_batch_size, ring_count, buffer pool stats
- Per-ring: same types with `ring` attribute
- Per-ring histogram: explicit bucket histogram with non-cumulative counts, min/max/sum/count

**Patterns**:
- `OTEL_APPEND` macro (same pattern as `PROM_APPEND`)
- Hand-written JSON via snprintf (no JSON library dependency)
- NaN/Inf clamped to 0.0
- `clock_gettime(CLOCK_REALTIME)` for `timeUnixNano`
- Cumulative sums use `startTimeUnixNano: "0"` (unknown origin)
- HTTP push: plain POSIX sockets, no TLS, blocking
- URL parsing: `http://host:port/path`, supports IPv4, IPv6, hostname resolution

**Gotchas**:
- HTTP push is plain HTTP (no TLS support)
- No keepalive, no chunked encoding
- Returns only HTTP status line, discards body
- Rejects unbracketed multi-colon authorities (ambiguous IPv6)

---

### Syslog Integration (`integrations/syslog/C/`) — NEW in v0.2.0

**Purpose**: Turnkey syslog forwarding for AuraIO logs via process-wide log handler

| File | Purpose | Tokens |
|------|---------|--------|
| `aura_syslog.h` | Syslog integration API | 569 |
| `aura_syslog.c` | Syslog forwarder implementation | 276 |
| `example.c` | Usage demo with custom ident | 1,182 |

**Configuration**:
```c
typedef struct {
    const char *ident;    // openlog ident (default: "auraio")
    int facility;         // Syslog facility (default: LOG_USER), -1 = use default
    int log_options;      // openlog flags (default: LOG_PID | LOG_NDELAY), -1 = use default
} aura_syslog_options_t;
```

**API**:
- `aura_syslog_install(options)` — Install syslog handler
- `aura_syslog_remove()` — Remove syslog handler

**Key Features**:
- **1:1 level mapping**: AuraIO log levels match syslog priorities exactly
- **Thread-safe**: syslog is POSIX thread-safe
- **Standalone**: Only depends on `auraio.h` and libc
- **Schema versioning**: `AURA_SYSLOG_SCHEMA_VERSION "v0"`, `STABILITY "experimental"`
- **Sentinel pattern**: `-1` for "use default" (allows `LOG_KERN` = 0)

**Implementation Pattern**:
```c
static void syslog_handler(int level, const char *msg, void *userdata) {
    (void)userdata;
    syslog(level, "%s", msg);  // "%s" prevents format-string injection
}
```

**Verification**: `journalctl -t auraio --no-pager -n 10`

---

### Log Handling API (C/C++/Rust) — NEW in v0.2.0

**Purpose**: Cross-language logging infrastructure for library and application logs

**C API** (`engine/include/auraio.h`, `engine/src/log.c`):
- **Levels**: `AURA_LOG_ERR`, `AURA_LOG_WARN`, `AURA_LOG_NOTICE`, `AURA_LOG_INFO`, `AURA_LOG_DEBUG` (syslog-compatible)
- **Handler type**: `void (*aura_log_fn)(int level, const char *msg, void *userdata)`
- **API**: `aura_set_log_handler(handler, userdata)`, `aura_log_emit(level, fmt, ...)`

**C++ API** (`engine/include/auraio/log.hpp`):
- **Level enum**: `auraio::LogLevel` (Error, Warning, Notice, Info, Debug)
- **Handler type**: `std::function<void(LogLevel, std::string_view)>`
- **API**: `auraio::set_log_handler(lambda)`, `auraio::clear_log_handler()`, `auraio::log_emit(level, msg)`
- **Implementation**: Header-only with inline variables (C++17), exception-safe trampoline

**Rust API** (`bindings/rust/auraio/src/log.rs`):
- **Level enum**: `pub enum LogLevel` with `Display` trait
- **Handler type**: `Box<dyn Fn(LogLevel, &str) + Send + 'static>`
- **API**: `set_log_handler(closure)`, `clear_log_handler()`, `log_emit(level, msg)`
- **Safety**: `panic::catch_unwind` prevents panics from crossing FFI

**Design Patterns**:
- **Process-wide handler**: Single global handler per process (thread-safe)
- **Silent by default**: No handler installed by default
- **Application logging**: `aura_log_emit()` enables app-level logging through same handler
- **FFI trampolines**: Bridge language boundaries safely (no exceptions/panics leaking)

**Examples**:
- `examples/C/log_handler.c` — Custom handler with timestamps and filtering
- `examples/cpp/log_handler.cpp` — Lambda handler with chrono timestamps
- `examples/rust/examples/log_handler.rs` — Closure handler with Unix timestamps

---

### BFFIO Benchmark Tool (`tools/BFFIO/`)

**Purpose**: FIO-compatible I/O benchmark that uses AuraIO as its sole engine, demonstrating AIMD adaptive tuning advantages over fixed-depth io_uring

**Entry point**: `tools/BFFIO/main.c`

| File | Purpose | Tokens |
|------|---------|--------|
| `main.c` | CLI entry point, engine lifecycle, job dispatch | 2,327 |
| `job_parser.h` | Config structs (`job_config_t`, `bench_config_t`, `rw_pattern_t`) | 750 |
| `job_parser.c` | .fio INI parser + CLI `--flag=value` parser with `[global]` inheritance | 4,925 |
| `workload.h` | Worker types (`io_ctx_t`, `io_ctx_pool_t`, `thread_ctx_t`, `file_set_t`) | 768 |
| `workload.c` | I/O submit loop, worker threads, file setup, convergence detection | 6,198 |
| `stats.h` | Per-thread atomic stats, histogram (200 buckets x 50us), sample arrays | 1,051 |
| `stats.c` | Atomic recording, CAS min/max, histogram percentiles, aggregation | 4,485 |
| `output.h` | Formatter API (`output_normal`, `output_json`) | 253 |
| `output.c` | FIO-compatible text + FIO 3.36 JSON with `"AuraIO"` section | 6,785 |
| `test_BFFIO.sh` | Functional test suite (20+ tests) | 2,309 |
| `run_baseline.sh` | FIO vs BFFIO comparison with delta report + regression detection | 5,180 |
| `Makefile` | Build system with libauraio.a dependency | 287 |

**New Features (v0.2.0)**:
- **Multi-file support** (`--nrfiles`, `--filesize`, `--file-service-type`):
  - `nrfiles`: Number of files to distribute I/O across (default: 1)
  - `filesize`: Per-file size (if unset, uses `size / nrfiles`)
  - `file_service_type`: `roundrobin` (default), `sequential`, `random`
  - Files created as `BFFIO.{0..N-1}.tmp` with real 0xA5 pattern
- **Adaptive latency sampling**: Budget-based recalibration (~100K samples/sec ceiling)
  - Eliminates `clock_gettime()` bottleneck at high IOPS (>1M)
  - PRNG-based selection avoids aliasing
  - Recalibrates every 65K I/Os based on estimated IOPS
- **Lock-free I/O context pool**: Treiber stack with atomic CAS (MPSC-safe)
- **Batched timestamps**: One `now_ns()` per batch (submit-side + TLS completion-side cache)

**Key Design Patterns**:
- One fresh AuraIO engine per job — clean AIMD convergence per workload
- Pre-allocated `io_ctx_pool_t` per thread — zero malloc on I/O hot path
- Per-thread `thread_stats_t` with relaxed atomics — no shared lock for stats
- CAS loops for min/max latency tracking
- xorshift64 PRNG for random offsets, rwmix decisions, and file selection
- Two-phase measurement: ramp (discarded) + steady-state (reported)

**AIMD Auto-Tuning (`--target-p99`)**:
- User specifies P99 latency ceiling (e.g., `--target-p99=2ms`)
- Engine starts at `initial_in_flight=4`, AIMD probes upward
- Auto-scales `numjobs` to match ring count (one thread per ring for convergence)
- Stats reset when all rings reach STEADY/CONVERGED phase
- Output shows `max concurrency=N at p99=X.XXms (target: Y.YYms)`

**FIO Compatibility**:
- Accepts `.fio` job files with `[global]` and `[job]` sections
- Supports all common CLI flags (`--rw`, `--bs`, `--size`, `--direct`, etc.)
- JSON output matches FIO 3.36 structure (`jobs[].read/write` with percentiles)
- Adds `"AuraIO"` section in JSON with `final_depth`, `phase`, `p99_ms`
- Text output matches FIO format (IOPS/BW line, latency summary, percentile table)

**Thread Model**:
- N worker threads (pthread): submit loop + `aura_wait(1ms)` + repeat
- Main thread: 1Hz timer for ramp detection, convergence polling, BW/IOPS sampling, runtime expiry
- Callbacks fire on any thread (hence spinlock-protected context pool)

**Gotchas**:
- File creation writes real 0xA5 pattern (defeats ext4 unwritten-extent optimization)
- O_DIRECT attempted first with buffered I/O fallback
- Histogram overflow bucket for latencies > 10ms
- `queue_depth` set to `iodepth * 2` (min 256) so AIMD has headroom below submission cap

See [docs/BFFIO.md](BFFIO.md) for full usage documentation.

---

### Ring Manager (`engine/src/adaptive_ring.c/.h`)

**Purpose**: io_uring wrapper with request tracking, batching, and per-ring adaptive control

**Entry point**: `engine/src/adaptive_ring.h`

| File | Purpose | Tokens |
|------|---------|--------|
| `engine/src/adaptive_ring.h` | Ring interface, request struct, latency sampling config | 2,296 |
| `engine/src/adaptive_ring.c` | Ring implementation, COOP_TASKRUN, batched CQE extraction, callback context tracking | 7,008 |

**Key Types**:
- `ring_ctx_t` - Per-ring context (io_uring, request pool, mutex, adaptive controller, `fixed_buf_inflight` counter)
- `aura_request_t` - Request with callback, timing, `uses_registered_buffer`/`uses_registered_file` flags (128-byte cache-line aligned)
- `aura_op_type_t` - Includes `AURA_OP_READ_FIXED` and `AURA_OP_WRITE_FIXED`

**Key Functions**:
- `ring_init()`, `ring_destroy()` - Lifecycle (destroy has 10-second drain timeout)
- `ring_submit_read()`, `ring_submit_write()`, `ring_submit_fsync()` - Submission
- `ring_submit_read_fixed()`, `ring_submit_write_fixed()` - Registered buffer I/O
- `ring_poll()`, `ring_wait()` - Completion processing (batched, up to 32 CQEs per lock hold)
- `ring_get_request()`, `ring_put_request()` - O(1) request pool
- `ring_in_callback_context()` - TLS depth counter for callback context detection
- `sqe_apply_fixed_file()` - Applies `IOSQE_FIXED_FILE` flag when using registered files

**Patterns**:
- Free stack for O(1) request allocation
- Lock released during callback to allow re-entrant submission
- SQPOLL with graceful fallback to normal mode
- `process_completion()` manages its own locking internally
- `IORING_SETUP_COOP_TASKRUN` for cooperative completions (kernel 5.19+)
- Selective request zeroing (only fields that vary between op types)
- Batched CQE extraction (up to 32 per lock hold, `RING_POLL_BATCH`)
- 1-in-8 latency sampling (`RING_LATENCY_SAMPLE_RATE`)
- Callback info saved **before** marking `pending=false` (prevents slot reuse during callback)
- `fixed_buf_inflight` decremented **after** callback returns

**Destroy Path**: (1) flush batched SQEs, (2) drain with retry-flush and 100ms waits (max 10 seconds), (3) destroy adaptive controller, (4) free resources, (5) exit io_uring. Flush-before-drain prevents `ring_wait()` from blocking on never-submitted SQEs. Timeout prevents infinite hang on stuck devices (e.g., hung NFS).

**Gotchas**:
- Request handle only valid until callback begins
- Callers must NOT hold lock when calling `process_completion()`
- Callbacks can submit new I/O (re-entry safe)
- `pending_count` momentarily inflated by 1 during callback execution
- `queued_sqes` is atomic for lock-free reads in `ring_should_flush()`

---

### Adaptive Engine (`engine/src/adaptive_engine.c/.h`)

**Purpose**: AIMD congestion control for automatic I/O tuning

**Entry point**: `engine/src/adaptive_engine.h`

| File | Purpose | Tokens |
|------|---------|--------|
| `engine/src/adaptive_engine.h` | Controller interface, constants, cache-line layout | 3,204 |
| `engine/src/adaptive_engine.c` | AIMD implementation, low-IOPS handling | 4,020 |

**Key Types**:
- `adaptive_controller_t` - Per-ring controller state
- `adaptive_phase_t` - State machine phases
- `adaptive_histogram_pair_t` - Double-buffered P99 latency tracking (50us buckets, 200 buckets)

**Key Functions**:
- `adaptive_init()`, `adaptive_destroy()` - Lifecycle
- `adaptive_tick()` - Called every 10ms, runs AIMD algorithm
- `adaptive_record_completion()` - Record latency sample (lock-free atomic)
- `adaptive_get_inflight_limit()`, `adaptive_get_batch_threshold()` - Current tuned values
- `adaptive_hist_swap()` - O(1) atomic index flip for double-buffered histograms

**AIMD State Machine**:
```
BASELINE (warmup, 100ms)
    ↓
PROBING (additive increase: +1/tick)
    ↓ plateau (efficiency_ratio ≤ epsilon for 3 ticks) OR latency spike (2 consecutive)
BACKOFF (multiplicative decrease: x0.8)
    ↓
SETTLING (wait 100ms)
    ↓
STEADY (maintain config)
    ↓ stable for 5s
CONVERGED (no more changes)
```

**Key Constants** (tuned for NVMe SSDs):
```c
ADAPTIVE_SAMPLE_INTERVAL_MS    = 10     // Tick every 10ms
ADAPTIVE_WARMUP_SAMPLES        = 10     // 100ms baseline
ADAPTIVE_AIMD_INCREASE         = 1      // Add 1 per tick
ADAPTIVE_AIMD_DECREASE         = 0.80   // Cut 20% on backoff
ADAPTIVE_LATENCY_GUARD_MULT    = 10.0   // Backoff if P99 > 10x baseline
ADAPTIVE_DEFAULT_LATENCY_GUARD = 10.0   // Hard ceiling: 10ms P99
```

**Double-Buffered Histogram**: O(1) `atomic_fetch_xor` flips active index. Tick reads P99 from the swapped-out histogram while new samples go to the other one. ~1-3 samples may be lost during swap (tolerable for statistical metrics).

**Low-IOPS Handling**: Extended sample window (100ms-1000ms) when fewer than 20 samples are available. P99 with 20 samples is effectively P95 (acceptable for slow storage).

**Efficiency Ratio**: Tracks `Δthroughput / Δin_flight` to detect plateau — when ratio ≤ epsilon for 3 consecutive ticks, transitions to SETTLING.

**Cache-Line Layout**: `adaptive_controller_t` hot fields (limits, counters) packed into cache line 0; tick-only state (phase, sliding windows) in subsequent lines

**Gotchas**:
- Histogram swap loses ~1-3 samples (race between pointer swap and reset)
- P99 requires minimum 20 samples for validity
- Low-IOPS handling: extended sample window when insufficient data
- Efficiency ratio bug fixed: now snapshots `prev_in_flight_limit` **before** state machine modifies it

---

### Buffer Pool (`engine/src/adaptive_buffer.c/.h`)

**Purpose**: Thread-safe 4KB-aligned buffer pool with size-class buckets

**Entry point**: `engine/src/adaptive_buffer.h`

| File | Purpose | Tokens |
|------|---------|--------|
| `engine/src/adaptive_buffer.h` | Pool interface | 1,433 |
| `engine/src/adaptive_buffer.c` | Pool implementation, TLS caching, CAS registration | 6,431 |

**Three-Tier Architecture**:
```
Thread Cache (TLS, no lock, ~10ns)
    ↓ cache miss
Shard (per-shard lock, ~50ns)
    ↓ shard empty
posix_memalign (slow path)
```

**Size Classes**: 16 classes from 4KB to 128MB (power-of-2). Fast-path cascade for 7 most common sizes (4KB-256KB) avoids `__builtin_clzl()` overhead.

**Auto-Scaling Shards**: 2-256 shards (~4 threads/shard target, power-of-2 rounding)

**Pool Destroy Race Prevention**:
- `pool_id` (global atomic generation counter) detects stale caches from address-reused pools
- `destroyed` atomic flag checked before dereferencing pool (re-checked in slow paths after initial check)
- `registrations_inflight` counter: incremented during cache registration, destroy waits for quiescence
- `cleanup_mutex` per cache: serializes buffer cleanup between TLS destructor and pool destroy — whoever gets the lock first handles buffers (sets `cleaned_up=true`), loser skips
- `thread_exited` flag: tracks whether TLS destructor has run, determines who frees the cache struct
- Pool destroy sets `cache->pool = NULL` to mark orphaned caches; `get_thread_cache()` detects and frees them

**Patterns**:
- `__builtin_clzl()` for O(1) size-to-class mapping
- Batch transfers (16 at a time) between cache and shard
- High-water mark limits cached buffers (default 256/shard)
- Lock-free TLS cache registration via CAS
- Pre-allocated metadata slots per shard (eliminates malloc on free path)

**Known Limitation**: A thread that has already passed the `destroyed` check in `get_thread_cache()` but not yet registered its cache may retain its TLS cache (~2KB) until thread exit. Acceptable for the shutdown path.

---

### Log Infrastructure (`engine/src/log.c/.h`)

**Purpose**: User-settable log callback so library never writes to stderr. Default is silent (NULL handler).

**Entry point**: `engine/src/log.h`

| File | Purpose | Tokens |
|------|---------|--------|
| `engine/src/log.h` | Internal log header (aura_log_fn, aura_log) | ~300 |
| `engine/src/log.c` | Library-wide log callback implementation | ~600 |

**Key Exports**:
- **`aura_set_log_handler()`**: Set global handler + userdata
- **`aura_log()`**: Emit log message (no-op if no handler)
- **Log levels**: `AURA_LOG_ERR=3`, `AURA_LOG_WARN=4` (match syslog)

**Key Patterns**:
- **Atomic handler storage**: `_Atomic(aura_log_fn)` + `memory_order_seq_cst` for cross-variable ordering
- **Thread-safe**: Handler can be called from any thread
- **256-byte buffer**: `vsnprintf()` formats message in fixed buffer (truncates if longer)

**Gotchas**:
- **seq_cst on both atomics**: Ensures consistent (handler, userdata) pair on weakly-ordered architectures (ARM/POWER)
- **Silent by default**: No handler = no output
- **Process-wide**: Handler is global, affects all engines

---

### Internal Utilities (`engine/src/internal.h`)

**Purpose**: Shared utilities across modules

| File | Purpose | Tokens |
|------|---------|--------|
| `engine/src/internal.h` | Timing, iovec helpers, TSan annotations | 525 |

**Exports**:
- `get_time_ns()` - Monotonic nanosecond clock (CLOCK_MONOTONIC)
- `iovec_total_len()` - Safe vectored I/O size with overflow check
- `TSAN_RELEASE()`/`TSAN_ACQUIRE()` - ThreadSanitizer annotations for io_uring's kernel-mediated synchronization

---

## Examples Cross-Language Parity

| Example | Purpose | C | C++ | Rust |
|---------|---------|:-:|:---:|:----:|
| **quickstart** | Minimal working example | ✓ | ✓ | ✓ |
| **simple_read** | Basic read with comprehensive stats | ✓ | ✓ | ✓ |
| **bulk_reader** | High-throughput concurrent reads | ✓ | ✓ | ✓ |
| **write_modes** | O_DIRECT vs buffered comparison | ✓ | ✓ | ✓ |
| **cancel_request** | Cancel in-flight operation | ✓ | ✓ | ✓ |
| **custom_config** | 5 workload configurations | ✓ | ✓ | ✓ |
| **vectored_io** | Scatter-gather readv/writev | ✓ | ✓ | ✓ |
| **registered_buffers** | Zero-copy with pre-registered buffers | ✓ | ✓ | ✓ |
| **file_copy** | Synchronous-style file copy | ✓ | ✗ | ✓ |
| **coroutine_copy** | C++20 coroutine async copy | ✗ | ✓ | ✗ |
| **async_copy** | Rust async/await file copy | ✗ | ✗ | ✓ |

**Complete parity (all 3 languages):** quickstart, simple_read, bulk_reader, write_modes, cancel_request, custom_config, vectored_io, registered_buffers

**Language-specific:** C++20 coroutines (coroutine_copy), Rust async/await (async_copy), C+Rust sync-style copy (file_copy)

---

## Data Flow

### Read Operation

```mermaid
sequenceDiagram
    participant User
    participant API as auraio.c
    participant Ring as adaptive_ring.c
    participant Kernel as io_uring

    User->>API: aura_read(engine, fd, buf, len, offset, cb, ud)
    API->>API: check fatal_submit_errno
    API->>API: select ring (CPU-aware via sched_getcpu)
    API->>API: submit_begin() — lock, allocate request
    API->>Ring: ring_submit_read()
    Ring->>Ring: get request slot (O(1) free stack)
    Ring->>Kernel: io_uring_prep_read()
    Ring->>Ring: increment queued_sqes
    API->>API: submit_end() — flush if batch threshold, unlock

    Note over Kernel: I/O completes

    User->>API: aura_wait()
    API->>Ring: ring_wait()
    Ring->>Kernel: io_uring_wait_cqe()
    Kernel-->>Ring: CQE batch (up to 32)
    Ring->>Ring: record latency (atomic)
    Ring->>Ring: release cq_lock
    Ring->>User: callback(result, user_data)
    Ring->>Ring: decrement fixed_buf_inflight (if registered)
    Ring->>Ring: acquire lock, return request slot
```

### Rust Callback Flow

```mermaid
sequenceDiagram
    participant App as Rust App
    participant Eng as Engine (Rust)
    participant CB as callback.rs
    participant C as C Library

    App->>Eng: engine.read(fd, buf, len, offset, closure)
    Eng->>CB: BoxedCallback::new(closure)
    CB->>CB: Box::into_raw() → *void
    Eng->>C: aura_read(engine, ..., trampoline, user_data)

    Note over C: I/O completes

    C->>CB: callback_trampoline(req, result, user_data)
    CB->>CB: Box::from_raw(user_data)
    CB->>App: closure(Result<usize>)
    CB->>CB: Drop context
```

### Adaptive Tuning Flow

```mermaid
sequenceDiagram
    participant Tick as Tick Thread
    participant Ctrl as adaptive_controller_t
    participant Hist as Double-Buffered Histogram

    loop Every 10ms
        Tick->>Ctrl: adaptive_tick()
        Ctrl->>Hist: atomic_fetch_xor (swap active index)
        Hist-->>Ctrl: old histogram (now inactive)
        Ctrl->>Ctrl: calculate P99 from old
        Ctrl->>Ctrl: calculate throughput
        Ctrl->>Ctrl: calculate efficiency_ratio
        Ctrl->>Ctrl: update sliding windows

        alt efficiency_ratio > epsilon
            Ctrl->>Ctrl: PROBING: in_flight += 1
        else latency > 10x baseline
            Ctrl->>Ctrl: BACKOFF: in_flight *= 0.8
        else plateau for 3 ticks
            Ctrl->>Ctrl: SETTLING → STEADY
        end

        Ctrl->>Hist: memset() inactive histogram to zero
    end
```

### Ring Selection (ADAPTIVE mode)

```mermaid
flowchart TD
    Submit["aura_read/write()"]
    Fatal{"fatal_submit_errno\nlatched?"}
    Fail["return NULL, errno = latched"]
    CPU["TLS-cached sched_getcpu()"]
    Local["Local ring = cpu % ring_count"]
    Gate1{"pending < 75%\nof in_flight_limit?"}
    Gate2{"pending > 2x\navg_ring_pending?"}
    Stay["Submit to local ring"]
    Spill["Power-of-two selection:\npick 2 random rings,\nuse lighter one"]
    Incr["Increment adaptive_spills"]

    Submit --> Fatal
    Fatal -->|Yes| Fail
    Fatal -->|No| CPU --> Local --> Gate1
    Gate1 -->|Yes| Stay
    Gate1 -->|No| Gate2
    Gate2 -->|Yes: outlier| Stay
    Gate2 -->|No| Spill --> Incr
```

## Optimization Techniques (Updated v0.2.0)

| Technique | Location | Impact |
|-----------|----------|--------|
| TLS-cached CPU routing | `auraio.c:select_ring()` | Refresh `sched_getcpu()` every 32 ops, not every op |
| Merged flush+poll | `auraio.c:aura_wait()` | Single-pass with early exit on first completion |
| COOP_TASKRUN | `adaptive_ring.c:ring_init()` | Cooperative completions, fewer context switches (kernel 5.19+) |
| Batched CQE extraction | `adaptive_ring.c:ring_poll()` | Up to 32 CQEs per lock hold, O(n/32) mutex overhead |
| Selective request zeroing | `adaptive_ring.c:ring_get_request()` | Only zero variant fields, skip fields overwritten by caller |
| 1-in-8 latency sampling | `adaptive_ring.c:process_completion()` | ~1250 samples/sec at 10K IOPS, sufficient for P99 |
| TLS buffer cache | `adaptive_buffer.c` | Zero-lock fast path (~10ns), CAS-based registration |
| Fast size-class cascade | `adaptive_buffer.c:size_to_class()` | Avoids `__builtin_clzl()` for 7 most common sizes |
| Cache-line layout | `adaptive_engine.h` | Hot atomics in cache line 0, cold tick state in line 1+ |
| Double-buffered histogram | `adaptive_engine.c` | O(1) atomic index flip, memset for reset |
| Eventfd draining | `auraio.c:aura_wait()` | Prevents spurious epoll wakeups after completions |
| Power-of-two ring spilling | `auraio.c:select_ring()` | ADAPTIVE mode: pick 2 random rings, use lighter one |
| Drift-free ticking | `auraio.c:tick_thread()` | `clock_nanosleep(TIMER_ABSTIME)` prevents drift from EINTR |
| TSan annotations | `internal.h` | `TSAN_RELEASE/ACQUIRE` for io_uring kernel synchronization |
| Submit begin/end pattern | `auraio.c` | Centralized lock+error handling, no request slot leaks |
| Transparent fixed-file | `auraio.c` | Auto-resolves registered files, no special API needed |
| Cache-line aligned requests | `adaptive_ring.h` | 128-byte struct prevents false sharing |
| **Rwlock fast path** (v0.2.0) | `auraio.c:aura_poll/wait()` | Skip rwlock when no buffers/files registered (~4.9% CPU saved) |
| **Eventfd skip** (v0.2.0) | `auraio.c:aura_poll/wait()` | Skip eventfd drain in single-thread mode (~5% improvement) |
| **Batch completion retirement** (v0.2.0) | `adaptive_ring.c:ring_retire_batch()` | N-to-1 lock acquisition ratio, process callbacks lock-free |
| **Single-thread mode** (v0.2.0) | `adaptive_ring.h:ring_lock/unlock()` | Skip mutexes when caller guarantees single-thread (~1-2% IOPS) |
| **Target-P99 probing** (v0.2.0) | `adaptive_engine.c:adaptive_tick()` | Continue probing below latency target even at plateau (depth 48→881) |
| **Peak in-flight tracking** (v0.2.0) | `auraio.c:tick_thread()` | High-water mark sampling, replaces optimal ceiling (Little's Law fix) |
| **Adaptive latency sampling** (v0.2.0 BFFIO) | `workload.c` | Budget-based recalibration (~100K samples/sec ceiling), eliminates clock overhead |
| **Lock-free I/O context pool** (v0.2.0 BFFIO) | `workload.c:io_ctx_pool_get/put()` | Treiber stack with atomic CAS (MPSC-safe) |

## Thread Safety

| Component | Mechanism | Notes |
|-----------|-----------|-------|
| Ring submission | `pthread_mutex_t` per ring | Released during callback |
| Ring completion | `pthread_mutex_t cq_lock` per ring | Separate from SQ lock, released before blocking wait |
| Request state | Atomic (`pending`) | Lock-free checks |
| Histogram recording | Atomic increments | No lock needed |
| Histogram swap | Atomic index flip (`fetch_xor`) | O(1) operation, memset for reset |
| Buffer TLS cache | Thread-local storage | Zero lock fast path |
| Buffer shards | Per-shard mutex | Round-robin selection |
| Buffer pool destroy | `cleanup_mutex` per cache + `destroyed` atomic | Coordinates TLS destructor vs pool destroy |
| Buffer pool registration | `registrations_inflight` atomic | Destroy waits for quiescence |
| Engine stats | Atomics with release/acquire | ARM/PowerPC safe |
| Fatal submit errno | Atomic CAS (latch first error) | Eventfd wakeup for propagation |
| Shutdown flag | `_Atomic bool shutting_down` | Set by destroy, checked by submit_begin |
| Fixed buf inflight | `_Atomic uint32_t` per ring | Track registered buffer ops for safe unregister |
| Queued SQEs | `_Atomic int` per ring | Lock-free reads in ring_should_flush() |
| C++ CallbackPool | Mutex-protected allocation | 8 shards, short-lived locks |
| C++ event_loop_mutex_ | `std::mutex` | Serializes poll/wait/run; submissions lock-free |
| C++ engine_alive_ | `shared_ptr<atomic<bool>>` | Buffer outlives engine safely |
| Rust Engine | `Send + Sync` via `Arc<EngineInner>` | C library handles locking |
| Rust IoFuture | `Arc<Mutex<IoState>>` + `Arc<AtomicBool>` | Waker notification + cancellation safety |
| Rust poll_lock | `Mutex<()>` | Serializes poll/wait/run |
| Rust callback trampoline | `catch_unwind` | Prevents cross-FFI panic unwinding |
| Ring selection counter | `_Atomic unsigned int` | Round-robin mode: atomic fetch-add |
| Average pending | `_Atomic int` | Updated by tick thread, read by ADAPTIVE select |
| Callback context | `_Thread_local int` | TLS depth counter for re-entrant callback detection |
| Deferred unregister | `_Atomic bool` pending flags | Coordinate drain between callback and polling threads |
| Log handler | `_Atomic(aura_log_fn)` + seq_cst | Process-wide, thread-safe |

### Lock Hierarchy (prevents deadlock)
1. Buffer pool shards (independent, no nesting)
2. Ring locks (independent, no nesting)
3. Engine pending_mutex (C++ only, short-lived)

### Thread Roles
- **Application threads**: Submit I/O (per-ring locks)
- **Poll thread**: Single thread calls poll/wait (releases lock for callbacks)
- **Tick thread**: Runs every 10ms, lock-free stats via atomics
- **SQPOLL threads** (optional): Kernel threads auto-submit SQEs
- **Rust background poller** (async pattern): Calls `engine.wait()` for future progress

## Test Infrastructure

### Unit Tests

| Test | Focus | File |
|------|-------|------|
| test_engine | AIMD algorithm, phase transitions | `tests/test_engine.c` |
| test_ring | Ring lifecycle, submission, completion | `tests/test_ring.c` |
| test_buffer | Buffer pool alloc/free, size classes | `tests/test_buffer.c` |
| test_stats | Observability API, per-ring stats, histograms | `tests/test_stats.c` |
| test_ring_select | Ring selection modes, ADAPTIVE spill verification | `tests/test_ring_select.c` |
| test_cpp | C++ bindings: RAII, callbacks, coroutines, concepts, deferred unregister, buffer-outlives-engine | `tests/test_cpp.cpp` |
| stress_test | Multi-threaded concurrent I/O | `tests/stress_test.cpp` |
| test_concurrency_stress | Multi-thread submit + aggressive poll stress | `tests/test_concurrency_stress.c` |
| test_coverage | Comprehensive coverage test suite | `tests/test_coverage.c` |
| test_otel | OpenTelemetry exporter tests | `tests/test_otel.c` |
| Rust tests | FFI bindings, safe API, async I/O, cancellation safety | `bindings/rust/auraio/src/lib.rs` |

### NEW: Adaptive Value Proof (`tests/adaptive_value.c`) — v0.2.0

**Purpose**: Prove AIMD beats static depth tuning across three scenarios

**Scenarios**:
1. **Noisy Neighbor**: Background writes create I/O pressure → AIMD adapts by reducing depth
2. **P99-Constrained Throughput**: Find max IOPS under P99 < 2ms constraint → AIMD auto-tunes
3. **Workload Phase Change**: Sequential 128K → Random 4K → AIMD reconverges for each phase

**Implementation**:
- Deterministic PRNG (xorshift64) for reproducible offsets
- Pre-generated offset tables (1M entries)
- Latency histogram: 200 buckets × 50us = 10ms max tracked
- Warmup period: 3s for AIMD convergence
- Measurement period: configurable (default 10s, `--quick` = 3s)

**Output Format**: Comparative table showing static depths (16, 64, 128, 256) vs adaptive

### NEW: Performance Regression Test (`tests/perf_regression.c`) — v0.2.0

**Purpose**: Measure AuraIO's per-operation overhead vs raw io_uring

**Baselines**:
1. **Naive raw io_uring**: Separate `io_uring_submit()` + `io_uring_wait_cqe()`, no flags
2. **Optimized raw io_uring**: `io_uring_submit_and_wait()` (merged syscall), COOP_TASKRUN + SINGLE_ISSUER, batched deadline checks
3. **AuraIO static**: Fixed depth matching raw-optimal, adaptive disabled
4. **AuraIO adaptive**: AIMD enabled, depth converges automatically

**Optimized Baseline Features**:
- **COOP_TASKRUN**: Completions delivered cooperatively (no async interrupts)
- **SINGLE_ISSUER**: Kernel skips cross-thread synchronization
- **Merged submit+wait**: Single syscall per batch
- **Batched deadline checks**: Check time every 1024 completions
- **Free-slot stack**: Prevents buffer aliasing on out-of-order completions

**Threshold Check**: Fails if worst-case IOPS overhead > `--threshold` (default 10%)

**Result**: Documents 19% structural overhead (mutexes, atomics, request pool, AIMD) relative to optimized raw io_uring

### Performance Benchmarks (`tests/perf_bench.c`)

Six benchmark modes:
- **Throughput**: 64K random reads, max inflight 256
- **Latency**: 4K serial reads, depth=1, min/avg/max/P99
- **Scalability**: Varying queue depth 4-128
- **Mixed**: 70% reads, 25% writes, 5% fsync
- **Syscall**: Measures ops per `io_uring_enter`
- **Buffer pool**: Multi-threaded alloc/free stress

Each benchmark runs in a separate fork to avoid io_uring kernel state contamination.

### Analysis Scripts

| Script | Purpose |
|--------|---------|
| `run_analysis.sh` | FIO comparison suite with apples-to-apples mode (recommended) |
| `run_deep_analysis.sh` | Flamegraphs, cachegrind, pahole, callgrind, perf c2c |
| `run_perf_test.sh` | Portable benchmark runner (earlier iteration) |

**`run_analysis.sh`** profiles: `--quick` (3s), `--standard` (5s), `--full` (10s). Generates Python report with FIO vs AuraIO comparison tables, percentage deltas, and key findings.

**`run_deep_analysis.sh`** phases: CPU flamegraphs, lock contention, cache behavior, struct layout (pahole), callgraph, false sharing detection. Generates automated optimization recommendations.

### Build Targets

```bash
# Core tests
make test              # C unit tests (parallel build + serial run)
make test-all          # C + C++ + Rust with unified summary
make test-sanitizers   # Valgrind + TSan + ASan combined summary

# Sanitizers
make test-memory       # TSan + ASan only
make test-strict       # Full suite (all + memory sanitizers)

# Coverage
make coverage          # Build/run tests with llvm-cov
make coverage-check    # Enforce minimum line coverage

# BFFIO benchmark tool
make BFFIO             # Build BFFIO
make BFFIO-test        # Run BFFIO functional tests (20+ tests)
make BFFIO-baseline    # FIO vs BFFIO comparison with delta report

# Benchmarks
make bench             # FIO comparison (5s/test)
make bench-quick       # Quick (3s/test)
make bench-deep        # Deep profiling (flamegraphs, cachegrind)

# Dependencies
make deps              # Interactive installer (kernel >= 6.0 required)
make deps-check        # Verify availability

# Integrations
make exporters         # Build Prometheus + OpenTelemetry C examples
```

## Performance Investigation (`investigations/bffio-performance-gap.md`) — NEW in v0.2.0

**Date**: 2026-02-08
**Environment**: OrbStack Linux VM (tmpfs), single-threaded

**Baseline Gap**:
- Single file: FIO 1,504K IOPS vs BFFIO 1,219K IOPS = **-19% gap**
- Multi-file (5 files): FIO 1,686K IOPS vs BFFIO 1,221K IOPS = **-28% gap**

**Root Cause**: AuraIO library overhead per I/O

**Per-I/O Cost Breakdown** (~200-250ns per I/O):

**Submit path** (~150ns):
- Ring selection (~2-3 atomics)
- `pthread_mutex_lock(&ring->lock)` (~20-30ns)
- Request pool pop from free stack
- SQE prep via io_uring API
- Atomic stores for `pending` flag and `pending_count`
- Auto-flush check + maybe `adaptive_record_submit()`
- `pthread_mutex_unlock(&ring->lock)` (~20-30ns)

**Completion path** (~100ns):
- `pthread_mutex_lock(&ring->cq_lock)` (~20-30ns)
- `io_uring_peek_cqe()` + `io_uring_cqe_seen()`
- `pthread_mutex_unlock(&ring->cq_lock)` (~20-30ns)
- `process_completion()` with callback, counter updates, request return
- Two more lock/unlock cycles for counter updates

**Total**: ~24% of wall time at 1.2M IOPS (matches observed gap)

**Optimizations Applied** (v0.2.0):
- Batch submit timestamps (one `now_ns()` per batch)
- Batch completion timestamps (TLS cache)
- Lock-free io_ctx_pool (Treiber stack)
- Adaptive latency sampling (~100K samples/sec ceiling)
- Rwlock fast path for deferred unregistration (~4.9% CPU saved)
- Eventfd skip in single-thread mode (~5% improvement)
- Combined impact: ~9.6% IOPS increase (1,081K → 1,185K)

**Remaining Gap**: 10% structural overhead vs optimized raw io_uring is acceptable trade-off for AIMD auto-tuning, observability, and cross-language bindings.

## Conventions

- **Naming**: Snake_case; `aura_` prefix for public, `ring_`/`adaptive_`/`buffer_` for internal
- **Types**: Opaque handles for public API, full structs internal
- **Memory**: Pre-allocate pools, avoid malloc on hot paths
- **Locking**: Release around callbacks, batch to reduce lock acquisitions
- **Errors**: Return negative errno (C), throw `auraio::Error` (C++), `Result<T>` (Rust)
- **C++ Style**: RAII, non-movable Engine, move-only Buffer, concepts for type safety
- **Rust Style**: RAII via Drop, `NonNull` for pointer safety, extension traits for async, `Arc<EngineInner>` for shared ownership
- **C11 Compliance**: `_Thread_local` (not `__thread`), `_Static_assert`, `<stdatomic.h>` with explicit memory orderings
- **Build**: `-Wall -Wextra -Wshadow -Wpedantic -std=c11 -O2 -fPIC -fvisibility=hidden`

## Gotchas

1. **Request handle lifetime**: Only valid until callback begins - do not store
2. **Callback deadlock**: Never call `aura_destroy()` from callback
3. **Shutdown order**: Stop worker threads before calling `aura_destroy()`
4. **Buffer pool TLS**: Only first pool accessed per thread gets cache benefit
5. **Registered buffer lifetime**: No in-flight I/O during unregister
6. **SQPOLL**: May silently fall back without root/CAP_SYS_NICE
7. **Low-IOPS devices**: Tick may skip if < 20 samples and < 100ms elapsed
8. **Histogram race (by design)**: ~1-3 samples lost during swap; uses memset for reset
9. **process_completion() locking**: Callers must NOT hold lock when calling it
10. **Rust inline functions**: `aura_buf`/`aura_buf_fixed` reimplemented (bindgen can't handle inline)
11. **Rust async polling**: Futures don't progress without background `engine.wait()` calls
12. **Rust RequestHandle**: Becomes dangling pointer after callback starts (most dangerous Rust gotcha)
13. **Prometheus histogram sum**: Estimated via midpoint (not exact)
14. **Coroutine ownership**: Task must remain alive until completion; destructor calls `std::terminate()` if still pending
15. **Coroutine result**: `Task<T>::get()` is destructive — moves result out, subsequent calls throw `std::logic_error`
16. **Registered file update**: `aura_update_file()` is non-atomic across rings — partial failure leaves inconsistent state
17. **C++ BufferRef const**: Explicit constructor from `const void*` prevents accidental use with read operations
18. **TSan ASLR**: Kernel >= 6.5 needs `setarch --addr-no-randomize` workaround
19. **Deferred unregister EBUSY**: Fixed-buffer submissions return `EBUSY` while unregister is draining
20. **C++ Buffer outlives Engine**: Safe — `engine_alive_` atomic flag triggers fallback to `free()`
21. **Event loop serialization**: `poll()`/`wait()`/`run()` are mutually exclusive (submissions remain lock-free)
22. **Callback context detection**: `ring_in_callback_context()` uses TLS depth counter — safe for nested callbacks
23. **Fatal submit latch**: Only first fatal `ring_flush()` error is latched; subsequent errors ignored; completions still drain
24. **Ring destroy timeout**: `ring_destroy()` gives up after 10 seconds (prevents infinite hang on stuck devices)
25. **Buffer pool destroy TLS leak**: Threads mid-registration may retain ~2KB TLS cache until thread exit
26. **Rust IoFuture drop**: Does NOT cancel the kernel operation — buffer must outlive kernel I/O
27. **Rust cancellation safety**: `request_consumed` atomic prevents cancelling a request whose handle is already invalid
28. **C++ Engine non-movable**: `event_loop_mutex_` cannot be moved; use `std::unique_ptr<Engine>` for heap allocation
29. **Prometheus overflow**: Returns `-(written * 2 + 4096)` estimate clamped to `INT_MIN`; check `errno` for `ENOBUFS` vs `ENOMEM`
30. **Rust poll/wait deadlock**: Never call poll/wait/run from within a completion callback (deadlocks on `poll_lock`)
31. **Overflow-safe bounds checking**: Registered buffer validation uses `offset >= iov_len || len > iov_len - offset` (not `offset + len > iov_len`)
32. **queued_sqes is atomic**: Changed from plain int to `_Atomic int` for lock-free reads in `ring_should_flush()`
33. **Log callback seq_cst**: Handler and userdata use `memory_order_seq_cst` for cross-variable ordering on ARM/POWER
34. **AIMD efficiency ratio timing**: `prev_in_flight_limit` snapshotted **before** state machine modifies it
35. **Partial io_uring_submit**: `queued_sqes -= submitted` handles partial submission (can happen under extreme load)
36. **Performance overhead** (NEW v0.2.0): AuraIO has ~19% overhead vs optimized raw io_uring (~200-250ns/op) due to mutexes, atomics, request pool, and AIMD. This is structural and acceptable trade-off for auto-tuning and observability. See `investigations/bffio-performance-gap.md`.
37. **Target-P99 probing** (NEW v0.2.0): AIMD now continues probing when P99 < target even at throughput plateau, allowing it to reach full saturation when latency headroom exists
38. **Peak in-flight metric** (NEW v0.2.0): `peak_in_flight` tracks actual observed max pending count (high-water mark), replacing `optimal_in_flight` ceiling which violated Little's Law
39. **Fsync API consolidated** (NEW v0.2.0): Single `aura_fsync(engine, fd, flags, callback, userdata)` with `AURA_FSYNC_DEFAULT` or `AURA_FSYNC_DATASYNC` flags
40. **Log handler process-wide** (NEW v0.2.0): `aura_set_log_handler()` installs global handler (thread-safe). Silent by default. Use `aura_log_emit()` for application logging.

## Navigation Guide

**To add a new public API function**:
1. Declare in `engine/include/auraio.h`
2. Implement in `engine/src/auraio.c` (use `submit_begin()`/`submit_end()` pattern for I/O ops)
3. Add C++ wrapper in `engine/include/auraio/engine.hpp`
4. Add Rust wrapper in `bindings/rust/auraio/src/engine.rs`
5. Re-export from `bindings/rust/auraio/src/lib.rs`

**To modify adaptive tuning behavior**:
1. Constants at top of `engine/src/adaptive_engine.h`
2. Algorithm in `adaptive_tick()` in `engine/src/adaptive_engine.c`

**To add a new I/O operation type**:
1. Add enum value to `aura_op_type_t` in `engine/src/adaptive_ring.h`
2. Add `ring_submit_*()` function in `engine/src/adaptive_ring.c`
3. Expose via public API in `auraio.c` and `auraio.h`
4. Add C++ method in `engine/include/auraio/engine.hpp`
5. Add awaitable in `engine/include/auraio/coro.hpp` if applicable
6. Add Rust method in `bindings/rust/auraio/src/engine.rs`
7. Add async variant in `bindings/rust/auraio/src/async_io.rs` if applicable

**To add a new BFFIO feature**:
1. Add config field to `job_config_t` in `tools/BFFIO/job_parser.h`
2. Parse it in `job_parser.c` (both CLI and .fio file paths)
3. Use it in `workload.c` I/O loop
4. Output it in `output.c` (both normal text and JSON)
5. Add test case in `test_BFFIO.sh`

**To add Prometheus metrics**:
1. Add stat to public API in `engine/include/auraio.h` (if new)
2. Add formatting in `integrations/prometheus/C/aura_prometheus.c`

**To add OpenTelemetry metrics**:
1. Add stat to public API in `engine/include/auraio.h` (if new)
2. Add formatting in `integrations/opentelemetry/C/aura_otel.c`

**To add a new Rust feature**:
1. Implement in appropriate `bindings/rust/auraio/src/*.rs` file
2. Re-export from `lib.rs`
3. Add tests in `lib.rs` test module
4. Add example in `examples/rust/examples/`

**Build and test**:
```bash
orb -m linux bash -c "make test"           # C tests
orb -m linux bash -c "make test-all"       # C + C++ + Rust
orb -m linux bash -c "make test-sanitizers" # Valgrind + TSan + ASan
orb -m linux bash -c "make bench"           # Performance vs FIO
```

## Historical Fixes (Pre-v0.2.0)

### 1. Atomics Hardening (Commit 53d6fa1)
- **Fixed**: TOCTOU in log.c handler/userdata pair, missing atomic_init in adaptive_engine.c, partial submit handling in adaptive_ring.c, buffer pool teardown race
- **Impact**: Log callback now uses seq_cst for cross-variable ordering; adaptive controller initializes atomics correctly; ring handles partial io_uring_submit() returns; buffer pool re-checks `destroyed` flag in slow paths
- **Files**: log.c, adaptive_engine.c, adaptive_ring.c, adaptive_buffer.c

### 2. Buffer Pool Teardown Races (Commits cddc408 + 94c8d6a + 53d6fa1)
- **Fixed**: Three-part fix: destroy-window cache UAF, cache destroy coordination, slow-path re-check
- **Impact**: Pool destroy never nulls `cache->pool` during traversal; uses atomic exchange loop to catch late registrations; alloc/free slow paths return ENXIO on destroyed pool
- **Files**: adaptive_buffer.c

### 3. AIMD Efficiency Ratio Correction (Commit 767f58f)
- **Fixed**: Efficiency ratio zero-delta bug (saved `prev_in_flight_limit` after state machine modified it), queued_sqes data race, log ordering on weak architectures
- **Impact**: ER now calculated correctly; AIMD no longer incorrectly detects plateaus; `queued_sqes` is atomic for lock-free reads; log handler/userdata use seq_cst
- **Files**: adaptive_engine.c, adaptive_ring.h, log.c

### 4. IoFuture Cancellation Race (Commit bcd0ed2)
- **Fixed**: Narrowed TOCTOU race in Rust `IoFuture::drop()` with second `request_consumed` check after lock release
- **Impact**: Race window reduced from "check under lock → release lock → cancel" to just "final check → cancel"; residual race documented and accepted (safe failure mode: EALREADY)
- **Files**: async_io.rs

### 5. Log Callback Implementation (Commit db1dc7a)
- **Fixed**: Added library-wide log callback API, removed dead fields (`cancel_requested`, `cancel_target`), added limitation docs
- **Impact**: Library is silent by default; users install handler to see diagnostics; stderr never written; process-wide handler
- **Files**: auraio.h (new public API), log.c, log.h, adaptive_ring.c

---

If cartographer helped you, consider starring: https://github.com/kingbootoshi/cartographer - please!